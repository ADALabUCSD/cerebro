{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fbcc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "import autokeras as ak\n",
    "\n",
    "from cerebro.nas.hphpmodel import HyperHyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3bcfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/21 20:36:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-21 20:36:21, Running 1 Workers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(SepalLengthCm=4.3, SepalWidthCm=3.0, PetalLengthCm=1.1, PetalWidthCm=0.1, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.4, SepalWidthCm=2.9, PetalLengthCm=1.4, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.4, SepalWidthCm=3.0, PetalLengthCm=1.3, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.4, SepalWidthCm=3.2, PetalLengthCm=1.3, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.5, SepalWidthCm=2.3, PetalLengthCm=1.3, PetalWidthCm=0.3, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.6, SepalWidthCm=3.1, PetalLengthCm=1.5, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.6, SepalWidthCm=3.4, PetalLengthCm=1.4, PetalWidthCm=0.3, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.7, SepalWidthCm=3.2, PetalLengthCm=1.3, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.8, SepalWidthCm=3.0, PetalLengthCm=1.4, PetalWidthCm=0.1, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.8, SepalWidthCm=3.0, PetalLengthCm=1.4, PetalWidthCm=0.3, Species=0, Species_OHE=SparseVector(3, {0: 1.0}))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .appName(\"NAS Iris\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from cerebro.backend import SparkBackend\n",
    "from cerebro.storage import LocalStore\n",
    "\n",
    "backend = SparkBackend(spark_context=sc, num_workers=1)\n",
    "store = LocalStore(prefix_path='/Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments')\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "df = spark.read.csv(\"/Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/Iris_clean.csv\", header=True, inferSchema=True)\n",
    "\n",
    "encoder = OneHotEncoderEstimator(dropLast=False)\n",
    "encoder.setInputCols([\"Species\"])\n",
    "encoder.setOutputCols([\"Species_OHE\"])\n",
    "\n",
    "encoder_model = encoder.fit(df)\n",
    "encoded = encoder_model.transform(df)\n",
    "train_df, test_df = encoded.randomSplit([0.8, 0.2])\n",
    "\n",
    "feature_columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "label_columns=['Species_OHE']\n",
    "\n",
    "input_node = [ak.StructuredDataInput() for c in feature_columns]\n",
    "embeddings = [ak.StructuredDataBlock()(innode) for innode in input_node]\n",
    "output_node = ak.Merge()([embeddings])\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "am = HyperHyperModel(\n",
    "    inputs=input_node, outputs=output_node\n",
    ")\n",
    "\n",
    "am.resource_bind(\n",
    "    backend=backend, \n",
    "    store=store,\n",
    "    feature_columns=feature_columns,\n",
    "    label_columns=label_columns,\n",
    "    evaluation_metric='accuracy', \n",
    ")\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4394f623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 11s]\n",
      "val_loss: 0.6208969354629517\n",
      "\n",
      "Best val_loss So Far: 0.6208969354629517\n",
      "Total elapsed time: 00h 06m 01s\n"
     ]
    }
   ],
   "source": [
    "am.tuner_bind(\n",
    "    tuner=\"randomsearch\", \n",
    "    hyperparameters=None, \n",
    "    objective=\"val_loss\",\n",
    "    max_trials=5,\n",
    "    overwrite=True,\n",
    ")\n",
    "rel = am.fit(train_df, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38859de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect best model training history.\n",
    "model_history = rel.get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631b5d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trial': <keras_tuner.engine.trial.Trial at 0x179248ed0>,\n",
       " 'train_loss': [1.1499926249186199,\n",
       "  1.0678984920183818,\n",
       "  1.091020663579305,\n",
       "  1.0541109045346577,\n",
       "  1.2112325032552083],\n",
       " 'train_accuracy': [0.375,\n",
       "  0.4791666567325592,\n",
       "  0.46875,\n",
       "  0.4583333432674408,\n",
       "  0.3958333432674408],\n",
       " 'val_loss': [1.151548147201538,\n",
       "  1.1615432500839233,\n",
       "  1.1486754417419434,\n",
       "  1.1191351413726807,\n",
       "  1.0912346839904785],\n",
       " 'val_accuracy': [0.25, 0.1875, 0.15625, 0.15625, 0.15625]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e43acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                 (0 + 1) / 1][Stage 16:>                 (0 + 1) / 1]2021-11-21 20:51:07.755889: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-21 20:51:07.756400: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-21 20:51:08.092117: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "[Stage 11:>                 (0 + 1) / 1][Stage 17:>                 (0 + 1) / 1]2021-11-21 20:51:11.861301: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-21 20:51:11.861840: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|  Species_OHE|    label_predicted|\n",
      "+-------------+-------------------+\n",
      "|(3,[0],[1.0])|0.25515392422676086|\n",
      "|(3,[0],[1.0])|0.25539514422416687|\n",
      "|(3,[0],[1.0])|0.25300097465515137|\n",
      "|(3,[0],[1.0])| 0.2515498101711273|\n",
      "|(3,[2],[1.0])|0.23178207874298096|\n",
      "|(3,[0],[1.0])|0.24540391564369202|\n",
      "|(3,[0],[1.0])|0.24609287083148956|\n",
      "|(3,[0],[1.0])|0.24646230041980743|\n",
      "|(3,[0],[1.0])|0.23969466984272003|\n",
      "|(3,[1],[1.0])|0.22828829288482666|\n",
      "+-------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 20:51:12.211978: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "output_df = rel.set_output_columns(['label_predicted']).transform(test_df)\n",
    "output_df.select('Species_OHE', 'label_predicted').show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642e4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rel.get_best_model().getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c833e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_category_encoding_2 (Mult (None, 1)            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          512         multi_category_encoding_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "multi_category_encoding_1 (Mult (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 1)            3           multi_category_encoding_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2048        normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_category_encoding_3 (Mult (None, 1)            0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 1)            3           multi_category_encoding_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           65600       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           128         normalization_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_category_encoding (MultiC (None, 1)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 64)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           128         multi_category_encoding[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           8224        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32)           128         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          16640       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 64)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 32)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 256)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           dropout[0][0]                    \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 384)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 3)            1155        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification_head_1 (Softmax) (None, 3)            0           dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 164,745\n",
      "Trainable params: 163,523\n",
      "Non-trainable params: 1,222\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2d08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "x = np.array(test_df.select(am.tuner.model_selection.feature_cols).collect())\n",
    "y = np.array(test_df.select(am.tuner.model_selection.label_cols).collect())\n",
    "x = [x[:,i,np.newaxis] for i in range(x.shape[1])]\n",
    "y = np.squeeze(y,1)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06a9567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25515392, 0.40035924, 0.3444868 ],\n",
       "       [0.25539514, 0.40188965, 0.34271517],\n",
       "       [0.25300097, 0.40175608, 0.34524292],\n",
       "       [0.25154984, 0.4032627 , 0.34518752],\n",
       "       [0.23178208, 0.41577715, 0.3524408 ],\n",
       "       [0.2454039 , 0.407093  , 0.34750307],\n",
       "       [0.24609289, 0.40734434, 0.34656283],\n",
       "       [0.24646229, 0.40723473, 0.346303  ],\n",
       "       [0.23969468, 0.41001257, 0.35029277],\n",
       "       [0.22828826, 0.4212397 , 0.350472  ],\n",
       "       [0.24255905, 0.409957  , 0.34748393],\n",
       "       [0.24561352, 0.41063094, 0.3437555 ],\n",
       "       [0.21964864, 0.43475255, 0.34559873],\n",
       "       [0.21666595, 0.42030928, 0.3630248 ],\n",
       "       [0.21594015, 0.42867857, 0.35538125],\n",
       "       [0.20978123, 0.43204698, 0.35817182],\n",
       "       [0.21055676, 0.4282944 , 0.3611488 ],\n",
       "       [0.21078843, 0.4452729 , 0.34393877],\n",
       "       [0.20773639, 0.43979594, 0.35246766],\n",
       "       [0.20402719, 0.4345966 , 0.36137617],\n",
       "       [0.20338775, 0.4247656 , 0.37184665],\n",
       "       [0.19934897, 0.44698316, 0.3536678 ],\n",
       "       [0.19800623, 0.43558842, 0.36640534],\n",
       "       [0.19856371, 0.43469587, 0.36674038],\n",
       "       [0.19527155, 0.45246193, 0.35226655],\n",
       "       [0.19479357, 0.43989775, 0.36530867],\n",
       "       [0.19281657, 0.4373952 , 0.36978823],\n",
       "       [0.18985908, 0.45306098, 0.35707992],\n",
       "       [0.1908913 , 0.43249527, 0.3766135 ],\n",
       "       [0.18197742, 0.46304727, 0.35497528],\n",
       "       [0.17486562, 0.46754622, 0.3575882 ],\n",
       "       [0.17684549, 0.46129024, 0.36186433],\n",
       "       [0.17303626, 0.46752527, 0.3594385 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "best_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b09ee3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_best_model = rel.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c18818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Species_OHE': {'spark_data_type': pyspark.sql.types.BinaryType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'SepalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'SepalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'PetalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'PetalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "spark_best_model._get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0e43fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField(SepalLengthCm,DoubleType,true),\n",
       " StructField(SepalWidthCm,DoubleType,true),\n",
       " StructField(PetalLengthCm,DoubleType,true),\n",
       " StructField(PetalWidthCm,DoubleType,true),\n",
       " StructField(Species,IntegerType,true),\n",
       " StructField(Species_OHE,VectorUDT,true)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "encoded.schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd985574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebro.backend.spark.util import _get_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c43d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SepalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'SepalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'PetalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'PetalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'Species': {'spark_data_type': pyspark.sql.types.IntegerType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'Species_OHE': {'spark_data_type': pyspark.ml.linalg.SparseVector,\n",
       "  'is_sparse_vector_only': True,\n",
       "  'shape': 3,\n",
       "  'intermediate_format': 'custom_sparse_format',\n",
       "  'max_size': 1}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "_get_metadata(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b24fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
